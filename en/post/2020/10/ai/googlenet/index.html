<!DOCTYPE html>

<html lang="en">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport" />
    <meta name="keywords"
        content="python,ai,deep learning,googlenet,pytorch," />
    <meta name="description"
        content="This post briefly introduces GoogLeNet and shares my experimental results after casually modifying the model." />
    <title>Neutrino&#39;s Blog: An Introduction to GoogLeNet and a Small Experiment </title>
    
    
    
    
    
    
        
            <link rel="alternate" hreflang="zh" href="https://tigercosmos.xyz/post/2020/10/ai/googlenet/">
        
            <link rel="alternate" hreflang="en" href="https://tigercosmos.xyz/en/post/2020/10/ai/googlenet/">
        
            <link rel="alternate" hreflang="jp" href="https://tigercosmos.xyz/jp/post/2020/10/ai/googlenet/">
        
        
        <link rel="alternate" hreflang="x-default" href="https://tigercosmos.xyz/post/2020/10/ai/googlenet/">
    
    <!-- favicon -->
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    
<link rel="stylesheet" href="/css/style.css">


        <!-- highlight -->
        <link id="hljs-light" rel="stylesheet"
            href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/atom-one-light.min.css" />
        <link id="hljs-dark" rel="stylesheet"
            href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/atom-one-dark.min.css" disabled />
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>

        <script>
            // Dark mode functionality
            function toggleDarkMode() {
                const html = document.documentElement;
                const currentTheme = html.getAttribute('data-theme');
                const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
                
                html.setAttribute('data-theme', newTheme);
                localStorage.setItem('theme', newTheme);
                
                // Update toggle button
                const toggle = document.getElementById('theme-toggle');
                toggle.textContent = newTheme === 'dark' ? '‚òÄÔ∏è' : 'üåô';
                
                // Toggle syntax highlighting theme
                toggleSyntaxHighlighting(newTheme);
            }

            // Toggle syntax highlighting theme
            function toggleSyntaxHighlighting(theme) {
                const lightTheme = document.getElementById('hljs-light');
                const darkTheme = document.getElementById('hljs-dark');
                
                if (theme === 'dark') {
                    lightTheme.disabled = true;
                    darkTheme.disabled = false;
                } else {
                    lightTheme.disabled = false;
                    darkTheme.disabled = true;
                }
            }

            // Initialize theme on page load
            function initializeTheme() {
                const savedTheme = localStorage.getItem('theme') || 'light';
                const html = document.documentElement;
                html.setAttribute('data-theme', savedTheme);
                
                const toggle = document.getElementById('theme-toggle');
                if (toggle) {
                    toggle.textContent = savedTheme === 'dark' ? '‚òÄÔ∏è' : 'üåô';
                }
                
                // Initialize syntax highlighting
                toggleSyntaxHighlighting(savedTheme);
            }

            window.addEventListener('DOMContentLoaded', function () {
                initializeTheme();
                const [
                    mainTitle,
                    mobileMenu,
                    mobileMainTitle,
                    mobileMenuBtn,
                    ipadMenuBtn,
                    aside,
                    closeBtn,
                ] = getEle(
                    '#main-title',
                    '.mobile-menu',
                    '.mobile-menu h3',
                    '.mobile-menu button',
                    '.ipad-menu',
                    'aside',
                    'aside .close',
                )
                const io = new IntersectionObserver(entries => {
                    if (entries[0].intersectionRatio <= 0) {
                        mobileMainTitle.classList.remove('invisibile')
                    } else {
                        mobileMainTitle.classList.add('invisibile')
                    }
                })
                io.observe(mainTitle)

                clickToggleAside(mobileMenuBtn)
                clickToggleAside(ipadMenuBtn)
                clickToggleAside(closeBtn, false)

                const isMenuVisible = window.getComputedStyle(mobileMenu).display !== 'none'
                if (isMenuVisible) document.body.style.background = 'none'

                function getEle(...args) {
                    return args.map(arg => document.querySelector(arg))
                }

                function clickToggleAside(btn, show = true) {
                    btn.addEventListener('click', function () {
                        if (show) {
                            aside.style.display = 'block'
                        } else {
                            aside.style.display = 'none'
                        }
                    })
                }
            })
        </script>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-MGLC34ST00"></script>
        <script>
            window.dataLayer = window.dataLayer || [];

            function gtag() {
                dataLayer.push(arguments);
            }
            gtag('js', new Date());

            gtag('config', 'G-MGLC34ST00');
        </script>
        <script type="text/javascript"
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async>
        </script>
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
            tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
            TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
            messageStyle: "none"
        }); 

        MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
            for(i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
            }
        });
    </script>

<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Neutrino's Blog" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>


<body style="background: url(https://cdn.jsdelivr.net/gh/frontendsophie/hexo-theme-autumn@1.0.0/source/img/button-bg.png) var(--bg-color)">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container">
        <header class="header">
    <nav class="mobile-menu" style="background: url(https://cdn.jsdelivr.net/gh/frontendsophie/hexo-theme-autumn@1.0.0/source/img/button-bg.png) var(--bg-color)">
        <h3 class="invisibile">
            <a href="/en/" class="logo">
                Neutrino&#39;s Blog
            </a>
        </h3>
        <button class="menu">menu</button>
    </nav>

    <button class="ipad-menu menu">menu</button>

    <h1 class="title" id="main-title">
        <a href="/en/" class="logo">
            Neutrino&#39;s Blog
        </a>
    </h1>
    <h2 class="desc">
        Code makes the world a better place
    </h2>

    <div class="links">
        <ul>
            
            <li>
                <a href="/about">
                    About
                </a>
            </li>
            
            <li>
                <a href="/navigation">
                    Navigation
                </a>
            </li>
            
            <li>
                <a href="/books">
                    Books
                </a>
            </li>
            
            <li>
                <a href="/donation">
                    Donation
                </a>
            </li>
            
            <li>
                <a href="/message">
                    Message
                </a>
            </li>
            
            <li>
                <a href="/atom.xml">
                    RSS
                </a>
            </li>
            
            <li>
                <a href="#" id="theme-toggle" onclick="toggleDarkMode()" title="Toggle dark mode">
                    üåô
                </a>
            </li>
            
            
            <li class="translation-switcher">
                
                <button class="translation-button" type="button" aria-label="Translations" title="Translations">
                    <svg viewBox="0 0 24 24" role="img" aria-hidden="true" focusable="false">
                        <path d="M12 2a10 10 0 1 0 10 10A10.01 10.01 0 0 0 12 2Zm7.94 9h-3.15a15.46 15.46 0 0 0-1.31-5.04A8.03 8.03 0 0 1 19.94 11ZM12 4.08A13.4 13.4 0 0 1 13.89 11H10.1A13.4 13.4 0 0 1 12 4.08ZM4.06 13h3.15a15.46 15.46 0 0 0 1.31 5.04A8.03 8.03 0 0 1 4.06 13ZM7.21 11H4.06A8.03 8.03 0 0 1 8.52 5.96 15.46 15.46 0 0 0 7.21 11ZM12 19.92A13.4 13.4 0 0 1 10.1 13h3.79A13.4 13.4 0 0 1 12 19.92ZM15.48 18.04A15.46 15.46 0 0 0 16.79 13h3.15A8.03 8.03 0 0 1 15.48 18.04ZM16.79 11a15.46 15.46 0 0 0-1.31-5.04A8.03 8.03 0 0 1 19.94 11Z"></path>
                    </svg>
                    <span class="translation-current" aria-hidden="true">en</span>
                </button>
                <div class="translation-menu" aria-label="Translation menu">
                    
                        
                            <a class="translation-lang" href="/post/2020/10/ai/googlenet/" hreflang="zh" lang="zh">zh</a>
                        
                    
                        
                            <span class="translation-lang is-current" lang="en">en</span>
                        
                    
                        
                            <a class="translation-lang" href="/jp/post/2020/10/ai/googlenet/" hreflang="jp" lang="jp">jp</a>
                        
                    
                </div>
            </li>
            
        </ul>
    </div>
</header>

        <main class="main">
            <article class="post">
    
    
    
    <h2 class="post-title">
        An Introduction to GoogLeNet and a Small Experiment
    </h2>
    <ul class="post-date">
        <li>
            2020-10-23
        </li>
        <li>
            Liu, An-Chi ÂäâÂÆâÈΩä
        </li>
        
        
        <li class="post-languages">
            <span class="post-languages-label">Lang</span>
            
                
                    <a class="translation-lang" href="/post/2020/10/ai/googlenet/" hreflang="zh" lang="zh">zh</a>
                
                ,
            
                
                    <span class="translation-lang is-current" lang="en">en</span>
                
                ,
            
                
                    <a class="translation-lang" href="/jp/post/2020/10/ai/googlenet/" hreflang="jp" lang="jp">jp</a>
                
                
            
            <span class="post-languages-note">
                (original ZH, translation powered by AI)
            </span>
        </li>
        
    </ul>
    <div class="post-content">
        <h2 id="Introduction"><a class="header-anchor" href="#Introduction">¬∂ </a>Introduction</h2>
<p>GoogLeNet was first introduced in Google‚Äôs paper, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.4842.pdf">Going deeper with convolutions</a>. The paper proposes the Inception V1 / GoogLeNet architecture, which ranked 1st in the classification track of ILSVRC-2014 (Top-5 Error = 6.67%). The model has only about 6.8 million parameters‚Äî9√ó fewer than AlexNet, and 20√ó fewer than VGG-16‚Äîso it is much more lightweight.</p>
<p>In this post, I briefly introduce GoogLeNet and share the results of a small experiment where I ‚Äúrandomly‚Äù modified the GoogLeNet model.</p>
<h2 id="GoogLeNet-Architecture-Overview"><a class="header-anchor" href="#GoogLeNet-Architecture-Overview">¬∂ </a>GoogLeNet Architecture Overview</h2>
<p>In many cases, it‚Äôs not obvious when we should use max-pooling versus convolution. GoogLeNet essentially uses them all at once: it applies convolutions with different kernel sizes and max-pooling in parallel, then concatenates their outputs. This structure is called an Inception module, and GoogLeNet is composed of many stacked Inception modules.</p>
<p><img src="https://user-images.githubusercontent.com/18013815/96935484-bd937500-14f6-11eb-9c1e-a87e2050bef4.png" alt="GoogLeNet"></p>
<p>The diagram above illustrates an Inception module. Another key idea in GoogLeNet is the concept of a <em>bottleneck</em>. In the figure, the left is a ‚Äústandard‚Äù Inception module, while the right is a modified version that introduces 1√ó1 convolutions. With 1√ó1 conv, we can greatly reduce the number of parameters‚Äîhence the term bottleneck.</p>
<p><img src="https://user-images.githubusercontent.com/18013815/96935814-75c11d80-14f7-11eb-9a73-70d52ce63e1d.png" alt="GoogLeNet Inception Parameters"></p>
<p>Without the bottleneck, the number of MACs (Multiply‚ÄìAccumulate Operations) is $((28\times 28\times 5\times 5)\times 192)\times 32 ‚âÉ 120$.</p>
<p>With the help of 1√ó1 conv to reduce computation, the MACs become the first layer $((28\times 28\times 1\times 1)\times 192)\times 16 ‚âÉ 2.4M$ plus the second layer $((28\times 28\times 5\times 5)\times 16)\times 32 ‚âÉ 10M $‚Äîabout $12.4M$ total. You can see that the MAC count drops by roughly an order of magnitude, and in practice the parameter count is also reduced by around 10√ó.</p>
<p><img src="https://user-images.githubusercontent.com/18013815/96936889-7fe41b80-14f9-11eb-8159-ffd97a34bd91.png" alt="GoogLeNet Architecture"></p>
<p>The figure above shows the overall GoogLeNet architecture. Roughly speaking, it contains nine Inception modules.</p>
<p><img src="https://user-images.githubusercontent.com/18013815/96937010-cafe2e80-14f9-11eb-8e33-d787171acff9.png" alt="GoogLeNet Parameter Table"></p>
<p>For detailed configuration, refer to the table above.</p>
<h2 id="Implementing-GoogLeNet-in-PyTorch"><a class="header-anchor" href="#Implementing-GoogLeNet-in-PyTorch">¬∂ </a>Implementing GoogLeNet in PyTorch</h2>
<p>The code isn‚Äôt long, so I‚Äôm pasting it in full. It‚Äôs basically the MNIST example from PyTorch, adapted to use CIFAR, and it uses the GoogLeNet module from the <a target="_blank" rel="noopener" href="https://github.com/weiaicunzai/pytorch-cifar100">pytorch-cifar100</a> project.</p>
<p>If you copy the code below, it should run directly. My environment is Python 3 + PyTorch 1.6 + CUDA 10.2.</p>
<details>
<pre><code class="language-python">from __future__ import print_function
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torchvision import transforms
from torch.optim.lr_scheduler import StepLR
import numpy as np

class Inception(nn.Module):
    def __init__(self, input_channels, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj):
        super().__init__()

        # 1x1conv branch
        self.b1 = nn.Sequential(
            nn.Conv2d(input_channels, n1x1, kernel_size=1),
            nn.BatchNorm2d(n1x1),
            nn.ReLU(inplace=True)
        )

        # 1x1conv -&gt; 3x3conv branch
        self.b2 = nn.Sequential(
            nn.Conv2d(input_channels, n3x3_reduce, kernel_size=1),
            nn.BatchNorm2d(n3x3_reduce),
            nn.ReLU(inplace=True),
            nn.Conv2d(n3x3_reduce, n3x3, kernel_size=3, padding=1),
            nn.BatchNorm2d(n3x3),
            nn.ReLU(inplace=True)
        )

        # 1x1conv -&gt; 5x5conv branch
        # we use 2 3x3 conv filters stacked instead
        # of 1 5x5 filters to obtain the same receptive
        # field with fewer parameters
        self.b3 = nn.Sequential(
            nn.Conv2d(input_channels, n5x5_reduce, kernel_size=1),
            nn.BatchNorm2d(n5x5_reduce),
            nn.ReLU(inplace=True),
            nn.Conv2d(n5x5_reduce, n5x5, kernel_size=3, padding=1),
            nn.BatchNorm2d(n5x5, n5x5),
            nn.ReLU(inplace=True),
            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),
            nn.BatchNorm2d(n5x5),
            nn.ReLU(inplace=True)
        )

        # 3x3pooling -&gt; 1x1conv
        # same conv
        self.b4 = nn.Sequential(
            nn.MaxPool2d(3, stride=1, padding=1),
            nn.Conv2d(input_channels, pool_proj, kernel_size=1),
            nn.BatchNorm2d(pool_proj),
            nn.ReLU(inplace=True)
        )

    def forward(self,\times):
        return torch.cat([self.b1(x), self.b2(x), self.b3(x), self.b4(x)], dim=1)


class GoogleNet(nn.Module):

    def __init__(self, num_class=100):
        super().__init__()
        self.prelayer = nn.Sequential(
            nn.Conv2d(3, 192, kernel_size=3, padding=1),
            nn.BatchNorm2d(192),
            nn.ReLU(inplace=True)
        )

        # although we only use 1 conv layer as prelayer,
        # we still use name a3, b3.......
        self.a3 = Inception(192, 64, 96, 128, 16, 32, 32)
        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)

        # &quot;&quot;&quot;In general, an Inception network is a network consisting of
        # modules of the above type stacked upon each other, with occasional
        # max-pooling layers with stride 2 to halve the resolution of the
        # grid&quot;&quot;&quot;
        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)

        self.a4 = Inception(480, 192, 96, 208, 16, 48, 64)
        self.b4 = Inception(512, 160, 112, 224, 24, 64, 64)
        self.c4 = Inception(512, 128, 128, 256, 24, 64, 64)
        self.d4 = Inception(512, 112, 144, 288, 32, 64, 64)
        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)

        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)
        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)

        # input feature size: 8*8*1024
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout2d(p=0.4)
        self.linear = nn.Linear(1024, num_class)

    def forward(self,\times):
        output = self.prelayer(x)
        output = self.a3(output)
        output = self.b3(output)

        output = self.maxpool(output)

        output = self.a4(output)
        output = self.b4(output)
        output = self.c4(output)
        output = self.d4(output)
        output = self.e4(output)

        output = self.maxpool(output)

        output = self.a5(output)
        output = self.b5(output)

        # &quot;&quot;&quot;It was found that a move from fully connected layers to
        # average pooling improved the top-1 accuracy by about 0.6%,
        # however the use of dropout remained essential even after
        # removing the fully connected layers.&quot;&quot;&quot;
        output = self.avgpool(output)
        output = self.dropout(output)
        output = output.view(output.size()[0], -1)
        output = self.linear(output)

        return output


def train(args, model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.cross_entropy(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))
            if args.dry_run:
                break


def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0

    top5count = 0

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model.forward(data)

            v, result = output.topk(5, 1, True, True)
            top5count += torch.eq(result, target.view(-1, 1)
                                  ).sum().int().item()

            # sum up batch loss
            test_loss += F.cross_entropy(output,
                                         target, reduction='sum').item()
            # get the index of the max log-probability
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: &#123;:.4f&#125;, Top 1 Error: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;), Top 5 Error: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;)\n'.format(
        test_loss,
        len(test_loader.dataset) - correct, len(test_loader.dataset),
        1 - correct / len(test_loader.dataset),
        len(test_loader.dataset) - top5count, len(test_loader.dataset),
        1 - top5count / len(test_loader.dataset),
    ))


def main():
    # Training settings
    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
    parser.add_argument('--batch-size', type=int, default=64, metavar='N',
                        help='input batch size for training (default:   64)')
    parser.add_argument('--test-batch-size', type=int, default=10, metavar='N',
                        help='input batch size for testing (default: 10)')
    parser.add_argument('--epochs', type=int, default=14, metavar='N',
                        help='number of epochs to train (default: 14)')
    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',
                        help='learning rate (default: 1.0)')
    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',
                        help='Learning rate step gamma (default: 0.7)')
    parser.add_argument('--no-cuda', action='store_true', default=False,
                        help='disables CUDA training')
    parser.add_argument('--dry-run', action='store_true', default=False,
                        help='quickly check a single pass')
    parser.add_argument('--seed', type=int, default=1, metavar='S',
                        help='random seed (default: 1)')
    parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                        help='how many batches to wait before logging training status')
    parser.add_argument('--save-model', action='store_true', default=False,
                        help='For Saving the current Model')
    args = parser.parse_args()
    use_cuda = not args.no_cuda and torch.cuda.is_available()

    torch.manual_seed(args.seed)

    device = torch.device(&quot;cuda:0&quot;)

    train_kwargs = &#123;'batch_size': args.batch_size&#125;
    test_kwargs = &#123;'batch_size': args.test_batch_size&#125;
    if use_cuda:
        cuda_kwargs = &#123;'num_workers': 2,
                       'pin_memory': True,
                       'shuffle': True&#125;
        train_kwargs.update(cuda_kwargs)
        test_kwargs.update(cuda_kwargs)

    transform = transforms.Compose(
        [transforms.RandomHorizontalFlip(p=0.5),
         transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    trainset = torchvision.datasets.CIFAR100(root='./data', train=True,
                                             download=True, transform=transform)
    trainloader = torch.utils.data.DataLoader(trainset, **train_kwargs)

    testset = torchvision.datasets.CIFAR100(root='./data', train=False,
                                            download=True, transform=transform)
    testloader = torch.utils.data.DataLoader(testset, **test_kwargs)

    model = GoogleNet().to(device)
    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)

    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)
    for epoch in range(1, args.epochs + 1):
        train(args, model, device, trainloader, optimizer, epoch)
        test(model, device, testloader)
        scheduler.step()

    if args.save_model:
        torch.save(model.state_dict(), &quot;mnist_cnn.pt&quot;)

    model_parameters = filter(lambda p: p.requires_grad, model.parameters())
    params = sum([np.prod(p.size()) for p in model_parameters])
    print(&quot;Parameters:&quot;, params)


if __name__ == '__main__':
    main()
</code></pre>
</details>
<h2 id="A-Small-GoogLeNet-Experiment"><a class="header-anchor" href="#A-Small-GoogLeNet-Experiment">¬∂ </a>A Small GoogLeNet Experiment</h2>
<p>Next, I ran a few experiments to see how GoogLeNet performs. I tested:</p>
<ul>
<li>The bottleneck version of GoogLeNet</li>
<li>A na√Øve version without bottlenecks (‚ÄúNa√Øve GoogLeNet‚Äù)</li>
<li>A ‚ÄúGoogLeNet Long‚Äù variant by arbitrarily adding two Inception modules</li>
<li>A ‚ÄúGoogLeNet Short‚Äù variant by arbitrarily removing some Inception layers</li>
</ul>
<p>The most aggressively reduced one is ‚ÄúGoogLeNet Short4‚Äù, which only has two Inception modules left. You can roughly infer the model size by looking at the parameter count.</p>
<p>I ran these models on both CIFAR-100 and CIFAR-10, and recorded Top-1 Error, Top-5 Error, Parameters, and Time.</p>
<p><strong>GoogLeNet on CIFAR-100</strong>:</p>
<table>
<thead>
<tr>
<th></th>
<th>Top   1 Error</th>
<th>Top 5 Error</th>
<th>Parameters</th>
<th>Time(14 epoch)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GoogleNet Na√Øve</td>
<td>0.36</td>
<td>0.09</td>
<td>65736148</td>
<td>52m38s</td>
</tr>
<tr>
<td>GoogleNet</td>
<td>0.34</td>
<td>0.10</td>
<td>6258500</td>
<td>29m8s</td>
</tr>
<tr>
<td>GoogleNet Long</td>
<td>0.35</td>
<td>0.10</td>
<td>9641924</td>
<td>36m41s</td>
</tr>
<tr>
<td>GoogleNet Short</td>
<td>0.32</td>
<td>0.09</td>
<td>5271652</td>
<td>23m11s</td>
</tr>
<tr>
<td>GoogleNet Short2</td>
<td>0.32</td>
<td>0.09</td>
<td>3523556</td>
<td>16m29s</td>
</tr>
<tr>
<td>GoogleNet Short3</td>
<td>0.36</td>
<td>0.11</td>
<td>1985220</td>
<td>9m3s</td>
</tr>
<tr>
<td>GoogleNet Short4</td>
<td>0.44</td>
<td>0.15</td>
<td>1650084</td>
<td>8m56s</td>
</tr>
</tbody>
</table>
<p><strong>GoogLeNet on CIFAR-10</strong>:</p>
<table>
<thead>
<tr>
<th></th>
<th>Top   1 Error</th>
<th>Top 5 Error</th>
<th>Parameters</th>
<th>Time(14 epoch)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GoogleNet Na√Øve</td>
<td>0.15</td>
<td>0.01</td>
<td>65291098</td>
<td>52m51s</td>
</tr>
<tr>
<td>GoogleNet</td>
<td>0.10</td>
<td>0.00</td>
<td>6166250</td>
<td>28m45s</td>
</tr>
<tr>
<td>GoogleNet Long</td>
<td>0.11</td>
<td>0.00</td>
<td>9549674</td>
<td>40m12s</td>
</tr>
<tr>
<td>GoogleNet Short</td>
<td>0.10</td>
<td>0.00</td>
<td>5179402</td>
<td>27m30s</td>
</tr>
<tr>
<td>GoogleNet Short2</td>
<td>0.10</td>
<td>0.00</td>
<td>3431306</td>
<td>31m57s</td>
</tr>
<tr>
<td>GoogleNet Short3</td>
<td>0.11</td>
<td>0.00</td>
<td>1892970</td>
<td>26m31s</td>
</tr>
<tr>
<td>GoogleNet Short4</td>
<td>0.15</td>
<td>0.01</td>
<td>1557834</td>
<td>25m30s</td>
</tr>
</tbody>
</table>
<p>First, you can see that the parameter count of the na√Øve version is indeed about 10√ó larger, but the accuracy is not dramatically different. Also, except for Short4, almost all variants perform similarly: on CIFAR-100, Top-1 Error is roughly around 0.35 and Top-5 Error around 0.10; on CIFAR-10, Top-1 Error is around 0.10 and Top-5 Error is around 0.00 (nearly zero).</p>
<p>My guess is that CIFAR-100 and CIFAR-10 are not complex enough, so for image classification the depth of the model doesn‚Äôt matter that much. In addition to depth, the number of channels also affects accuracy. If the number of channels is large enough, perhaps you don‚Äôt need such a deep network. I also tried randomly adding max-pooling layers and dropout layers to GoogLeNet, but the errors were largely the same. This suggests that for image classification, the model itself has fairly high tolerance.</p>
<p>Of course, the conclusions above only apply to simple datasets. On more challenging benchmarks, even a few percentage points of accuracy matter a lot‚Äîtiny differences after the decimal point often represent countless engineering ideas and hard work. Still, the most impressive part of GoogLeNet is that it removes a huge number of parameters while achieving nearly the same accuracy!</p>

    </div>
    

    <a href="/books/beyond-just-coding-book.html" onclick="gtag('event', 'click_book_banner', {'link_url': this.href});">
        <picture>
            <!-- For screens wider than 600px -->
            <source media="(min-width: 600px)" srcset="/img/new-book-banner.png" class="new-book-banner-image">
            
            <!-- Default image for smaller screens -->
            <img src="/img/new-book-banner-small.png" alt="„ÄäÁ®ãÂºèË®≠Ë®àÂéü‰æÜ‰∏çÂè™ÊúâÂØ´ CODEÔºÅ„ÄãÊñ∞Êõ∏Ê©´ÂπÖÂª£Âëä" class="new-book-banner-image">
        </picture>
    </a>

   
    <div class="post-tag">
        tags:&nbsp;
        
            <a href="/en/tags/python/">
                python
            </a>,&nbsp;
        
            <a href="/en/tags/ai/">
                ai
            </a>,&nbsp;
        
            <a href="/en/tags/deep-learning/">
                deep learning
            </a>,&nbsp;
        
            <a href="/en/tags/googlenet/">
                googlenet
            </a>,&nbsp;
        
            <a href="/en/tags/pytorch/">
                pytorch
            </a>,&nbsp;
        
    </div>
    
<script>
    hljs.configure({
        useBR: false
    });
    document.querySelectorAll('.code').forEach((block) => {
        hljs.highlightBlock(block);
    });
    document.querySelectorAll('pre code').forEach((block) => {
        hljs.highlightBlock(block);
    });
</script>

<p class="post-end-line-small">
    Â¶ÇÊûúÊÇ®Ë¶∫ÂæóÈÄôÁØáÊñáÁ´†ÊúâÂπ´Âä©ÔºåÊÇ®ÂèØ‰ª• <a href="/donation/">Ë¥äÂä©</a> ÈÄôÂÄãÁ∂≤Á´ôÔºÅ
    Ê≠§Â§ñ‰πüÂèØ‰ª•Âéª <a href="/message">ÂÖ®Á´ôÁïôË®ÄÊùø</a> ‰æÜÁïôË®ÄÂñîÔºÅ
</p>

        </main>
        <aside class="aside">
            <div class="close"></div>
            <section class="aside-section">
                
<h2>About Me</h2>
<img alt="my photo" width="80%" src="/img/selfie3.jpg">
<div class="about">
  Liu, An-Chi ÂäâÂÆâÈΩä<br>
  Software Engineer<br>
  @tigercosmos
</div>


            </section>
            <section class="aside-section">
                
    <h2>Êñ∞Êõ∏‰∏äÂ∏Ç</h2>
    <a href="/books/beyond-just-coding-book.html" onclick="gtag('event', 'click_book_side', {'link_url': this.href});">
        <img alt="Êñ∞Êõ∏Êé®Âª£Ôºö„ÄäÁ®ãÂºèË®≠Ë®àÂéü‰æÜ‰∏çÂè™ÊúâÂØ´ CODEÔºÅÈäúÊé•Â≠∏Ê†°ËàáËÅ∑Â†¥ÁöÑ‰∫îÂ†ÇËªüÈ´îÈñãÁôºÂØ¶ÁøíË™≤„Äã" width="100%" src="/img/new-book-banner-small.png">
    </a>

            </section>
            
                <section class="aside-section">
                    <h2>TOC</h2>
<div class="toc-container">
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GoogLeNet-Architecture-Overview"><span class="toc-text">GoogLeNet Architecture Overview</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Implementing-GoogLeNet-in-PyTorch"><span class="toc-text">Implementing GoogLeNet in PyTorch</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A-Small-GoogLeNet-Experiment"><span class="toc-text">A Small GoogLeNet Experiment</span></a></li></ol>
</div>
                </section>
            
            <section class="aside-section">
                
<div class="recent-post">
  <h2>Recent Posts</h2>
  <ul>
    
    
    
    <li>
      <a href="/en/post/2025/10/japan/find-swe-job-in-japan-2025/">
        My 2025 Fall Mid-Level SWE Job Hunt in Japan and Taiwan
      </a>
    </li>
    
    <li>
      <a href="/en/post/2025/02/algorithm/bts-tree-delete/">
        Deleting a Node in a Binary Search Tree (LeetCode 450: Delete Node in a BST)
      </a>
    </li>
    
    <li>
      <a href="/en/post/2024/12/c++/hash/">
        An Introduction to std::hash in C++
      </a>
    </li>
    
    <li>
      <a href="/en/post/2024/11/c++/std-string-advanced/">
        C++ std::string Advanced: One Article to Get You Comfortable with Strings!
      </a>
    </li>
    
    <li>
      <a href="/en/post/2023/12/japan/learn-japanese-n4/">
        My Three-Month JLPT N4 Self-Study Experience
      </a>
    </li>
    
    <li>
      <a href="/en/post/2023/07/c++/template-for-std-containter-conversion/">
        Converting Between Container Types with C++ Template Functions (std::list&lt;int&gt; to std::vector&lt;double&gt;)
      </a>
    </li>
    
    <li>
      <a href="/en/post/2023/06/c++/condition-variable-cpp/">
        A Simple Example of Condition Variables in C++
      </a>
    </li>
    
    <li>
      <a href="/en/post/2023/06/c++/std-string-beginner/">
        C++ std::string for Beginners: One Article to Get You Comfortable with Strings!
      </a>
    </li>
    
    <li>
      <a href="/en/post/2023/06/c++/stringview/">
        Still Using const std::string&amp;? Try std::string_view!
      </a>
    </li>
    
    <li>
      <a href="/en/post/2023/05/c++/googletest/">
        Writing C++ Unit Tests with GoogleTest
      </a>
    </li>
    
  </ul>
</div>


            </section>
            <section class="aside-section">
                
<h2>Search</h2>
<input class="search-input" type="text" placeholder="Search on Google">
<script>
    const input = document.getElementsByClassName("search-input");
    input[0].addEventListener("keyup", function (event) {
        if (event.keyCode === 13) {
            event.preventDefault();
            window.open("https://www.google.com/search?&q=site%3Atigercosmos.xyz+" + input[0].value);
        }
    });
</script>

            </section>
            <section class="aside-section">
                <div>
     <h2>Ë¥äÂä©ÂØ´‰Ωú</h2>
     Ë¨ùË¨ùÊÇ®ÁöÑÂçîÂä©ÔºåË´ã‰ΩúËÄÖÂñù‰∏ÄÊùØÂíñÂï°ÔºåËÉΩËÆì‰ΩúËÄÖÁî®‰æÜÊõ¥ÊúâÂãïÂäõÁÇ∫ËÆÄËÄÖÊèê‰æõÂìÅË≥™Êõ¥Âä†ÂÑ™ËâØÁöÑÊñáÁ´†ËàáÈñ±ËÆÄÁí∞Â¢É
     <div align="center">
          <a href='/donation'><img
                    src="https://user-images.githubusercontent.com/18013815/79032455-21002a00-7bd9-11ea-920f-354c6133cc2a.png"
                    width="80%"></a>
     </div>
</div>
            </section>
            <section class="aside-section">
                
    <h2>Archives</h2>

    <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2025/">2025</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2024/">2024</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2023/">2023</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2022/">2022</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2021/">2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2020/">2020</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2019/">2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2018/">2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2017/">2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2016/">2016</a><span class="archive-list-count">2</span></li></ul>


            </section>
            <section class="aside-section tag">
                
    <h2>Tags</h2>

    <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/ai/" rel="tag">ai</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/algorithm/" rel="tag">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/art/" rel="tag">art</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/atmospheric-sciences/" rel="tag">atmospheric sciences</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/bime/" rel="tag">bime</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/binary-search-tree/" rel="tag">binary search tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/c/" rel="tag">c++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/cmake/" rel="tag">cmake</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/company/" rel="tag">company</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/computer-animation/" rel="tag">computer animation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/computer-science/" rel="tag">computer science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/computer-vision/" rel="tag">computer vision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/condition-variable/" rel="tag">condition variable</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/courses/" rel="tag">courses</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/cublas/" rel="tag">cublas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/cuda/" rel="tag">cuda</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/cudnn/" rel="tag">cudnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/data-structures/" rel="tag">data structures</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/deep-learning/" rel="tag">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/fine-arts-club/" rel="tag">fine arts club</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/googlenet/" rel="tag">googlenet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/googletest/" rel="tag">googletest</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/graduate-school/" rel="tag">graduate school</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/hash/" rel="tag">hash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/header-only/" rel="tag">header-only</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/japan/" rel="tag">japan</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/japanese/" rel="tag">japanese</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/jlpt/" rel="tag">jlpt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/job/" rel="tag">job</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/language-learning/" rel="tag">language learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/leetcode-450/" rel="tag">leetcode 450</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/master-s/" rel="tag">master's</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/nchc/" rel="tag">nchc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/nctu-observations-and-reflections/" rel="tag">nctu observations and reflections</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/nlp/" rel="tag">nlp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/ntu/" rel="tag">ntu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/ntu-observations-and-reflections/" rel="tag">ntu observations and reflections</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/nycu-icse/" rel="tag">nycu icse</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/optimization/" rel="tag">optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/parallel-programming/" rel="tag">parallel programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/programming/" rel="tag">programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/projects/" rel="tag">projects</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/pytorch/" rel="tag">pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/red-black-tree/" rel="tag">red black tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/small-vector/" rel="tag">small vector</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/software-engineer/" rel="tag">software engineer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/sso/" rel="tag">sso</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/std-hash/" rel="tag">std::hash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/std-unordered-map/" rel="tag">std::unordered_map</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/std-unordered-set/" rel="tag">std::unordered_set</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/string/" rel="tag">string</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/string-view/" rel="tag">string_view</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/t2/" rel="tag">t2</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/taiwan/" rel="tag">taiwan</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/teaching-assistant/" rel="tag">teaching assistant</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/template/" rel="tag">template</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/tensorflow/" rel="tag">tensorflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/thoughts/" rel="tag">thoughts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/tokyo/" rel="tag">tokyo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/unit-test/" rel="tag">unit test</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/university/" rel="tag">university</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/vector/" rel="tag">vector</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/vgg16/" rel="tag">vgg16</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/work/" rel="tag">work</a></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/xr-project/" rel="tag">xr project</a></li></ul>


            </section>
        </aside>
    </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>

</html>
